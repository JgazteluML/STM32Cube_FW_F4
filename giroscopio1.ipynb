{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBtT1Rx/Yy1p08bsOGeYN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JgazteluML/STM32Cube_FW_F4/blob/master/giroscopio1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJk4Wxm7T232",
        "outputId": "88956677-8e47-4cc6-f55a-24f7e3608246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "5/5 - 1s - loss: 37803.0703 - accuracy: 0.3256 - val_loss: 1978.5164 - val_accuracy: 0.4848 - 791ms/epoch - 158ms/step\n",
            "Epoch 2/60\n",
            "5/5 - 0s - loss: 9096.5234 - accuracy: 0.4729 - val_loss: 4336.3828 - val_accuracy: 0.4545 - 64ms/epoch - 13ms/step\n",
            "Epoch 3/60\n",
            "5/5 - 0s - loss: 6801.3262 - accuracy: 0.5116 - val_loss: 799.0781 - val_accuracy: 0.5152 - 55ms/epoch - 11ms/step\n",
            "Epoch 4/60\n",
            "5/5 - 0s - loss: 2802.1152 - accuracy: 0.5969 - val_loss: 398.7759 - val_accuracy: 0.6061 - 51ms/epoch - 10ms/step\n",
            "Epoch 5/60\n",
            "5/5 - 0s - loss: 5501.4487 - accuracy: 0.5271 - val_loss: 257.9020 - val_accuracy: 0.6061 - 50ms/epoch - 10ms/step\n",
            "Epoch 6/60\n",
            "5/5 - 0s - loss: 2695.3662 - accuracy: 0.6512 - val_loss: 131.2227 - val_accuracy: 0.6061 - 48ms/epoch - 10ms/step\n",
            "Epoch 7/60\n",
            "5/5 - 0s - loss: 709.9233 - accuracy: 0.6899 - val_loss: 46.3459 - val_accuracy: 0.6970 - 50ms/epoch - 10ms/step\n",
            "Epoch 8/60\n",
            "5/5 - 0s - loss: 590.1388 - accuracy: 0.7597 - val_loss: 16.1773 - val_accuracy: 0.8485 - 53ms/epoch - 11ms/step\n",
            "Epoch 9/60\n",
            "5/5 - 0s - loss: 1733.2461 - accuracy: 0.7752 - val_loss: 12.5081 - val_accuracy: 1.0000 - 67ms/epoch - 13ms/step\n",
            "Epoch 10/60\n",
            "5/5 - 0s - loss: 1048.6605 - accuracy: 0.7674 - val_loss: 12.4313 - val_accuracy: 1.0000 - 61ms/epoch - 12ms/step\n",
            "Epoch 11/60\n",
            "5/5 - 0s - loss: 477.7141 - accuracy: 0.7984 - val_loss: 12.3886 - val_accuracy: 1.0000 - 54ms/epoch - 11ms/step\n",
            "Epoch 12/60\n",
            "5/5 - 0s - loss: 847.5927 - accuracy: 0.8527 - val_loss: 12.3621 - val_accuracy: 1.0000 - 53ms/epoch - 11ms/step\n",
            "Epoch 13/60\n",
            "5/5 - 0s - loss: 616.2413 - accuracy: 0.8217 - val_loss: 12.3319 - val_accuracy: 1.0000 - 55ms/epoch - 11ms/step\n",
            "Epoch 14/60\n",
            "5/5 - 0s - loss: 708.4969 - accuracy: 0.8295 - val_loss: 12.2804 - val_accuracy: 1.0000 - 52ms/epoch - 10ms/step\n",
            "Epoch 15/60\n",
            "5/5 - 0s - loss: 159.4405 - accuracy: 0.8527 - val_loss: 12.2265 - val_accuracy: 1.0000 - 51ms/epoch - 10ms/step\n",
            "Epoch 16/60\n",
            "5/5 - 0s - loss: 497.5706 - accuracy: 0.8837 - val_loss: 12.1810 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 17/60\n",
            "5/5 - 0s - loss: 284.5000 - accuracy: 0.8450 - val_loss: 12.1146 - val_accuracy: 1.0000 - 53ms/epoch - 11ms/step\n",
            "Epoch 18/60\n",
            "5/5 - 0s - loss: 985.5786 - accuracy: 0.8217 - val_loss: 12.0998 - val_accuracy: 1.0000 - 52ms/epoch - 10ms/step\n",
            "Epoch 19/60\n",
            "5/5 - 0s - loss: 907.3724 - accuracy: 0.8527 - val_loss: 12.0720 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 20/60\n",
            "5/5 - 0s - loss: 1168.2948 - accuracy: 0.8372 - val_loss: 12.0339 - val_accuracy: 1.0000 - 69ms/epoch - 14ms/step\n",
            "Epoch 21/60\n",
            "5/5 - 0s - loss: 238.2893 - accuracy: 0.8605 - val_loss: 12.0130 - val_accuracy: 1.0000 - 52ms/epoch - 10ms/step\n",
            "Epoch 22/60\n",
            "5/5 - 0s - loss: 164.3771 - accuracy: 0.8372 - val_loss: 12.0167 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 23/60\n",
            "5/5 - 0s - loss: 705.9861 - accuracy: 0.8605 - val_loss: 12.0376 - val_accuracy: 1.0000 - 54ms/epoch - 11ms/step\n",
            "Epoch 24/60\n",
            "5/5 - 0s - loss: 761.1007 - accuracy: 0.8527 - val_loss: 12.0831 - val_accuracy: 1.0000 - 56ms/epoch - 11ms/step\n",
            "Epoch 25/60\n",
            "5/5 - 0s - loss: 842.8221 - accuracy: 0.8217 - val_loss: 12.1448 - val_accuracy: 1.0000 - 49ms/epoch - 10ms/step\n",
            "Epoch 26/60\n",
            "5/5 - 0s - loss: 368.6057 - accuracy: 0.8682 - val_loss: 12.2005 - val_accuracy: 1.0000 - 51ms/epoch - 10ms/step\n",
            "Epoch 27/60\n",
            "5/5 - 0s - loss: 821.4202 - accuracy: 0.8605 - val_loss: 12.1525 - val_accuracy: 1.0000 - 63ms/epoch - 13ms/step\n",
            "Epoch 28/60\n",
            "5/5 - 0s - loss: 220.6498 - accuracy: 0.7907 - val_loss: 12.2320 - val_accuracy: 1.0000 - 62ms/epoch - 12ms/step\n",
            "Epoch 29/60\n",
            "5/5 - 0s - loss: 1095.8380 - accuracy: 0.8062 - val_loss: 12.2652 - val_accuracy: 1.0000 - 70ms/epoch - 14ms/step\n",
            "Epoch 30/60\n",
            "5/5 - 0s - loss: 530.6567 - accuracy: 0.8527 - val_loss: 12.3692 - val_accuracy: 1.0000 - 76ms/epoch - 15ms/step\n",
            "Epoch 31/60\n",
            "5/5 - 0s - loss: 181.8595 - accuracy: 0.8605 - val_loss: 12.4935 - val_accuracy: 1.0000 - 54ms/epoch - 11ms/step\n",
            "Epoch 32/60\n",
            "5/5 - 0s - loss: 402.9896 - accuracy: 0.8682 - val_loss: 12.6181 - val_accuracy: 1.0000 - 48ms/epoch - 10ms/step\n",
            "Epoch 33/60\n",
            "5/5 - 0s - loss: 190.5032 - accuracy: 0.8837 - val_loss: 12.6904 - val_accuracy: 1.0000 - 49ms/epoch - 10ms/step\n",
            "Epoch 34/60\n",
            "5/5 - 0s - loss: 331.0385 - accuracy: 0.8605 - val_loss: 12.7259 - val_accuracy: 1.0000 - 54ms/epoch - 11ms/step\n",
            "Epoch 35/60\n",
            "5/5 - 0s - loss: 411.1651 - accuracy: 0.8837 - val_loss: 12.7456 - val_accuracy: 1.0000 - 54ms/epoch - 11ms/step\n",
            "Epoch 36/60\n",
            "5/5 - 0s - loss: 65.6339 - accuracy: 0.8605 - val_loss: 12.7682 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 37/60\n",
            "5/5 - 0s - loss: 46.8947 - accuracy: 0.9070 - val_loss: 12.7815 - val_accuracy: 1.0000 - 63ms/epoch - 13ms/step\n",
            "Epoch 38/60\n",
            "5/5 - 0s - loss: 344.4535 - accuracy: 0.9070 - val_loss: 12.7792 - val_accuracy: 1.0000 - 56ms/epoch - 11ms/step\n",
            "Epoch 39/60\n",
            "5/5 - 0s - loss: 71.9486 - accuracy: 0.8992 - val_loss: 12.7709 - val_accuracy: 1.0000 - 53ms/epoch - 11ms/step\n",
            "Epoch 40/60\n",
            "5/5 - 0s - loss: 306.7252 - accuracy: 0.8682 - val_loss: 12.7435 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 41/60\n",
            "5/5 - 0s - loss: 248.9248 - accuracy: 0.9070 - val_loss: 12.6999 - val_accuracy: 1.0000 - 69ms/epoch - 14ms/step\n",
            "Epoch 42/60\n",
            "5/5 - 0s - loss: 30.5186 - accuracy: 0.9147 - val_loss: 12.6566 - val_accuracy: 1.0000 - 62ms/epoch - 12ms/step\n",
            "Epoch 43/60\n",
            "5/5 - 0s - loss: 102.6672 - accuracy: 0.9535 - val_loss: 12.6403 - val_accuracy: 1.0000 - 52ms/epoch - 10ms/step\n",
            "Epoch 44/60\n",
            "5/5 - 0s - loss: 144.1241 - accuracy: 0.9225 - val_loss: 12.6226 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 45/60\n",
            "5/5 - 0s - loss: 568.8141 - accuracy: 0.9457 - val_loss: 12.5834 - val_accuracy: 1.0000 - 55ms/epoch - 11ms/step\n",
            "Epoch 46/60\n",
            "5/5 - 0s - loss: 706.6620 - accuracy: 0.9302 - val_loss: 12.5127 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 47/60\n",
            "5/5 - 0s - loss: 35.8236 - accuracy: 0.9147 - val_loss: 12.5108 - val_accuracy: 1.0000 - 51ms/epoch - 10ms/step\n",
            "Epoch 48/60\n",
            "5/5 - 0s - loss: 122.4132 - accuracy: 0.9225 - val_loss: 12.5370 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 49/60\n",
            "5/5 - 0s - loss: 29.8807 - accuracy: 0.9302 - val_loss: 12.5592 - val_accuracy: 1.0000 - 51ms/epoch - 10ms/step\n",
            "Epoch 50/60\n",
            "5/5 - 0s - loss: 138.1156 - accuracy: 0.9380 - val_loss: 12.5782 - val_accuracy: 1.0000 - 53ms/epoch - 11ms/step\n",
            "Epoch 51/60\n",
            "5/5 - 0s - loss: 265.2904 - accuracy: 0.9147 - val_loss: 12.5888 - val_accuracy: 1.0000 - 52ms/epoch - 10ms/step\n",
            "Epoch 52/60\n",
            "5/5 - 0s - loss: 792.8269 - accuracy: 0.9612 - val_loss: 12.5910 - val_accuracy: 1.0000 - 52ms/epoch - 10ms/step\n",
            "Epoch 53/60\n",
            "5/5 - 0s - loss: 20.1358 - accuracy: 0.9690 - val_loss: 12.5883 - val_accuracy: 1.0000 - 50ms/epoch - 10ms/step\n",
            "Epoch 54/60\n",
            "5/5 - 0s - loss: 365.1104 - accuracy: 0.9302 - val_loss: 12.5697 - val_accuracy: 1.0000 - 51ms/epoch - 10ms/step\n",
            "Epoch 55/60\n",
            "5/5 - 0s - loss: 161.0951 - accuracy: 0.9457 - val_loss: 12.5462 - val_accuracy: 1.0000 - 51ms/epoch - 10ms/step\n",
            "Epoch 56/60\n",
            "5/5 - 0s - loss: 26.4033 - accuracy: 0.9457 - val_loss: 12.5358 - val_accuracy: 1.0000 - 56ms/epoch - 11ms/step\n",
            "Epoch 57/60\n",
            "5/5 - 0s - loss: 19.4071 - accuracy: 0.9767 - val_loss: 12.5330 - val_accuracy: 1.0000 - 59ms/epoch - 12ms/step\n",
            "Epoch 58/60\n",
            "5/5 - 0s - loss: 33.0172 - accuracy: 0.9070 - val_loss: 12.5306 - val_accuracy: 1.0000 - 70ms/epoch - 14ms/step\n",
            "Epoch 59/60\n",
            "5/5 - 0s - loss: 18.7017 - accuracy: 0.9845 - val_loss: 12.5330 - val_accuracy: 1.0000 - 53ms/epoch - 11ms/step\n",
            "Epoch 60/60\n",
            "5/5 - 0s - loss: 239.0092 - accuracy: 0.9767 - val_loss: 12.5215 - val_accuracy: 1.0000 - 52ms/epoch - 10ms/step\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import datetime\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "API_KEY = 'ei_7640d6d5870987290c6670e19996c09dde1e16a3382ba358f2463e1a53312fa1'\n",
        "\n",
        "def download_data(url):\n",
        "    response = requests.get(url, headers={'x-api-key': API_KEY})\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        print(response.content)\n",
        "        raise ConnectionError('Could not download data file')\n",
        "\n",
        "X = download_data('https://studio.edgeimpulse.com/v1/api/113048/training/65/x')\n",
        "Y = download_data('https://studio.edgeimpulse.com/v1/api/113048/training/65/y')\n",
        "with open('x_train.npy', 'wb') as file:\n",
        "    file.write(X)\n",
        "with open('y_train.npy', 'wb') as file:\n",
        "    file.write(Y)\n",
        "X = np.load('x_train.npy')\n",
        "Y = np.load('y_train.npy')[:,0]\n",
        "import sys, os, random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Set random seeds for repeatable results\n",
        "RANDOM_SEED = 3\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "classes_values = [ \"Horizontal\", \"agitar_ArribaAbajo\", \"agitar_IzqDer\" ]\n",
        "classes = len(classes_values)\n",
        "\n",
        "Y = tf.keras.utils.to_categorical(Y - 1, classes)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "input_length = X_train[0].shape[0]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "\n",
        "def get_reshape_function(reshape_to):\n",
        "    def reshape(image, label):\n",
        "        return tf.reshape(image, reshape_to), label\n",
        "    return reshape\n",
        "\n",
        "callbacks = []\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed, ReLU, Softmax\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "EPOCHS = 60\n",
        "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "\n",
        "# model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='relu',\n",
        "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(30, activation='relu',\n",
        "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(classes, name='y_pred', activation='softmax'))\n",
        "\n",
        "# this controls the learning rate\n",
        "opt = Adam(learning_rate=0.004, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir=log_dir, histogram_freq=1)\n",
        "hparams_callback = hp.KerasCallback(log_dir, {\n",
        "    'num_relu_units': 512,\n",
        "    'dropout': 0.2\n",
        "})\n",
        "\n",
        "\n",
        "# train the neural network\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=2, callbacks=[tensorboard_callback, hparams_callback])\n",
        "#          .get_class_weights(Y_train))\n",
        "\n",
        "# Use this flag to disable per-channel quantization for a model.\n",
        "# This can reduce RAM usage for convolutional models, but may have\n",
        "# an impact on accuracy.\n",
        "disable_per_channel_quantization = False\n",
        "# Save the model to disk\n",
        "model.save('saved_model')\n",
        "\n",
        "!tensorboard dev upload --logdir ./logs \\\n",
        "  --name \"giroscope\" \\\n",
        "  --description \"Training results from https://colab.research.google.com/drive/1gLFeZ8u3Hh-eTY2BzacgVbAlMRKyC79g#scrollTo=MJk4Wxm7T232 \\\n",
        "  --one_shot"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsesnvSjT4W0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}